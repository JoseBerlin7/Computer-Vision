{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import optim"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1757408723392
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "ds = Datastore.get(ws, \"cvdatastore\")\n",
        "\n",
        "dataset = Dataset.File.from_files(path=(ds, \"Plant_leaf_diseases_dataset_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/**\"))\n",
        "\n",
        "mount_context = dataset.mount()\n",
        "mount_context.start()\n",
        "\n",
        "data_path = mount_context.mount_point"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1757406028107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As the data is already augmented we will go with no aug transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((244,244)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=data_path,transform=transform)\n",
        "\n",
        "train_ratio = int(0.8*len(full_dataset))\n",
        "test_ratio = len(full_dataset)-train_ratio\n",
        "\n",
        "train_ds, test_ds = random_split(full_dataset, [train_ratio, test_ratio])\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=6, pin_memory=True, prefetch_factor=2)\n",
        "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=6, pin_memory=True, prefetch_factor=2)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1757409104560
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model & eval definition\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, len(full_dataset.classes))\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1757409104722
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training \n",
        "epochs = 5\n",
        "scalar = GradScaler(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        \n",
        "        with autocast(device):\n",
        "            out = model(images)\n",
        "            loss = criterion(out, labels)\n",
        "\n",
        "        scalar.scale(loss).backward()\n",
        "        scalar.step(optimizer)\n",
        "        scalar.update()\n",
        "        \n",
        "        running_loss += loss.item()*images.size(0)\n",
        "    epoch_loss = running_loss/len(train_loader.dataset)\n",
        "    \n",
        "    model.eval()\n",
        "    correct, total = 0,0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device, non_blocking = True),labels.to(device, non_blocking = True)\n",
        "\n",
        "            with autocast(device):\n",
        "                out = model(images)\n",
        "            \n",
        "            _, pred = torch.max(out,1)\n",
        "            total += labels.size(0)\n",
        "            correct += (pred==labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch:{epoch+1}/{epochs}\\tepoch Loss:{epoch_loss}\\tAccuracy:{100*correct/total}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch:1/5\tepoch Loss:0.5388048978232655\tAccuracy:94.68206212392259\nEpoch:2/5\tepoch Loss:0.18615872945554413\tAccuracy:95.26752317449991\nEpoch:3/5\tepoch Loss:0.1449804331865254\tAccuracy:95.87737843551797\nEpoch:4/5\tepoch Loss:0.1262207428202296\tAccuracy:96.18637176776711\nEpoch:5/5\tepoch Loss:0.11370420669204502\tAccuracy:96.49536510001626\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1757409285651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mount_context.stop()\n",
        "\n",
        "model.eval()\n",
        "torch.save(model.state_dict,\"leaf_disease_model.pth\")"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1757276740544
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn seaborn"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Valuation metrics\n",
        "all_preds, all_labels = [], []\n",
        "    \n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        \n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "conf_mat = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(conf_mat, annot=False,cmap=\"Blues\", xticklabels=full_dataset.classes, yticklabels=full_dataset.classes)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(classification_report(all_labels, all_preds, target_names=full_dataset.classes))\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1757409011202
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.10 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}